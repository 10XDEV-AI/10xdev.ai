{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfbeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy\n",
    "import matplotlib\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "text_file = open(\"API_key.txt\", \"r\")\n",
    "\n",
    "def get_embedding(task):\n",
    "    time.sleep(2)\n",
    "    response = openai.Embedding.create(\n",
    "            input=task,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def search_functions(df, code_query):\n",
    "    embedding = get_embedding(code_query)\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    res = df.sort_values('similarities', ascending=False).head(100)\n",
    "    return res\n",
    "\n",
    "def split_file(filename,blocks):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = 0\n",
    "    prev_end_line = -2\n",
    "    prev_line=\" \"\n",
    "    for i, line in enumerate(lines):\n",
    "        if  line[0]!=\" \" and (len(prev_line.replace(\" \", \"\").replace(\"\\t\", \"\"))==1) :\n",
    "            stripped_line = line.replace(\" \", \"\").replace(\"\\t\", \"\")\n",
    "            prev_end_line = i\n",
    "            extracted_lines = lines[start_line:prev_end_line]\n",
    "\n",
    "            # join the extracted lines into a string\n",
    "            extracted_text = \"\".join(extracted_lines)\n",
    "            if extracted_text != \"\":\n",
    "                blocks.append([filename,start_line,prev_end_line,extracted_text])\n",
    "            #print(filename)\n",
    "\n",
    "            start_line = i\n",
    "        prev_line=line\n",
    "    extracted_lines = lines[prev_end_line:len(lines)]\n",
    "    # join the extracted lines into a string\n",
    "    extracted_text = \"\".join(extracted_lines)\n",
    "    if prev_end_line==-2:\n",
    "        prev_end_line=0\n",
    "    blocks.append([filename,prev_end_line,len(lines),extracted_text])\n",
    "    return blocks\n",
    "\n",
    "import shutil\n",
    "\n",
    "def create_clone(path):\n",
    "    # Remove folder if it exists\n",
    "    if os.path.exists(\"AIFiles\"):\n",
    "        shutil.rmtree(\"AIFiles\")\n",
    "    # Create folder\n",
    "    os.mkdir(\"AIFiles\")\n",
    "    # Copy everything in path to AIFiles\n",
    "    for filename in os.listdir(path):\n",
    "        src = os.path.join(path, filename)\n",
    "        dst = os.path.join(\"AIFiles\", filename)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "def train_AI(path):\n",
    "    print(\"Training AI\")\n",
    "    create_clone(path)\n",
    "    file_paths_details = []\n",
    "    Files_to_ignore = open(path+\"/.AIIgnore\", \"r\").read().splitlines()\n",
    "    print(\"Files and directories to ignore:\")\n",
    "    print(Files_to_ignore)\n",
    "\n",
    "    for root, directories, files in os.walk(path):\n",
    "        # Exclude any directories that appear in the ignore list\n",
    "        directories[:] = [d for d in directories if d not in Files_to_ignore]\n",
    "        print(\"Directories:\", directories)\n",
    "        for filename in files:\n",
    "            if filename not in Files_to_ignore:\n",
    "                print(filename)\n",
    "                # Append the path to each file to the file_paths list\n",
    "                file_paths_details.append(os.path.join(root, filename))\n",
    "    df4 = pd.DataFrame(file_paths_details)\n",
    "    df4.columns = [\"filepath\"]\n",
    "    #create a new column that has last synced time\n",
    "    df4['last_sync'] = time.time()\n",
    "    #use the lambda function to get the last modified time of the file os.getmtime fielname\n",
    "    df4['last_updated'] = df4.filepath.apply(lambda x: os.path.getmtime(x))\n",
    "    df4.to_csv(\"df4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05432e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AI\n",
      "Files and directories to ignore:\n",
      "['node_modules']\n",
      "Directories: []\n",
      "index.html\n",
      "styles.css\n",
      "dummy_1.txt\n",
      "login-page.js\n",
      ".AIIgnore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_AI('/Users/prathameshsutone/Desktop/PR_Raiser/repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4770ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_patch(patch_string):\n",
    "    lines = patch_string.split(\"\\n\")\n",
    "    commands = []\n",
    "    i=0\n",
    "    j=0\n",
    "    \n",
    "    lines = [line for line in patch_string.split(\"\\n\") if not line.startswith(\"\\\\\")]\n",
    "\n",
    "    \n",
    "    while (i < len(lines)-1):\n",
    "        #print(\"Ho\")\n",
    "        #print(lines[i][0])\n",
    "        if(lines[i][0] not in['>','<',\"\\\\\",'-']):\n",
    "            #print(\"Command = \" + lines[i])\n",
    "            j=i+1\n",
    "            #print(j)\n",
    "            if lines[i].find(\"a\") > 0:\n",
    "                    cmd = lines[i].split(\"a\")[0]\n",
    "                    new_line_numbers = tuple(map(int, lines[i].split(\"a\")[1].split(\",\")))\n",
    "                    count = new_line_numbers[1]-new_line_numbers[0]\n",
    "                    #print(count)\n",
    "                    new_lines = lines[i+1:i+count+2]\n",
    "                    command = (\"add\", cmd, new_line_numbers,new_lines)\n",
    "                    #print(command)\n",
    "            elif lines[i].find(\"c\") > 0:\n",
    "                cmd = lines[i].split(\"c\")\n",
    "                pre = cmd[0]\n",
    "                post = cmd[1]\n",
    "                new_count=0\n",
    "                old_count=0\n",
    "                \n",
    "                if pre.find(\",\")>0:\n",
    "                    old_line_numbers = tuple(map(int, lines[i].split(\"c\")[0].split(\",\")))\n",
    "                    old_count = old_line_numbers[1]-old_line_numbers[0]+1\n",
    "                    #old_lines = lines[i+1:i+old_count+1]\n",
    "                else:\n",
    "                    old_line_numbers = int(pre)\n",
    "                    #print(type(old_line_numbers))\n",
    "                    old_count=1\n",
    "                    #old_lines = lines[i+1:i+old_count+2]\n",
    "                \n",
    "                \n",
    "                if post.find(\",\")>0:\n",
    "                    #print(\"Pre = \")\n",
    "                    #print(pre)\n",
    "                    new_line_numbers = tuple(map(int, lines[i].split(\"c\")[1].split(\",\")))\n",
    "                    new_count = new_line_numbers[1]-new_line_numbers[0]+1\n",
    "                    #new_lines = lines[i+1:i+new_count+2]\n",
    "                else:\n",
    "                    new_line_numbers = int(post)\n",
    "                    new_count=1\n",
    "                    #new_lines = lines[i+1:i+new_count+1]\n",
    "               \n",
    "                old_lines = [line[2:] for line in lines[i+1:i+old_count+1]]\n",
    "                new_lines = [line[2:] for line in lines[i+old_count+2:i+old_count+new_count+2]]\n",
    "                command = (\"change\", old_line_numbers, new_line_numbers,old_lines,new_lines)\n",
    "                #print(command)\n",
    "            elif lines[i].find(\"d\") > 0:\n",
    "                cmd = lines[i].split(\"d\")[0]\n",
    "                old_line_numbers = tuple(map(int, lines[i].split(\"d\")[0].split(\",\")))\n",
    "                count = old_line_numbers[1]-old_line_numbers[0]\n",
    "                #print(count)\n",
    "                new_lines = lines[i+1:i+count+2]\n",
    "                command = (\"del\", cmd, new_line_numbers,old_lines)\n",
    "                #print(command)\n",
    "            \n",
    "            commands.append(command)\n",
    "            while((j<len(lines)-1) and lines[j][0] in ['>','<',\"\\\\\",'-']):\n",
    "                #print(str(j-i)+\" |\"+lines[j])\n",
    "                j+=1\n",
    "            #print(\" \")\n",
    "        i=j\n",
    "    return commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fe32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_patch(patch_string):\n",
    "    lines = patch_string.split(\"\\n\")\n",
    "    commands = []\n",
    "    i=0\n",
    "    j=0\n",
    "    \n",
    "    lines = [line for line in patch_string.split(\"\\n\") if not line.startswith(\"\\\\\")]\n",
    "\n",
    "    \n",
    "    while (i < len(lines)-1):\n",
    "        #print(\"Ho\")\n",
    "        #print(lines[i][0])\n",
    "        if(lines[i][0] not in['>','<',\"\\\\\",'-']):\n",
    "            #print(\"Command = \" + lines[i])\n",
    "            j=i+1\n",
    "            #print(j)\n",
    "            if lines[i].find(\"a\") > 0:\n",
    "                    cmd = lines[i].split(\"a\")[0]\n",
    "                    new_line_numbers = tuple(map(int, lines[i].split(\"a\")[1].split(\",\")))\n",
    "                    count = new_line_numbers[1]-new_line_numbers[0]\n",
    "                    #print(count)\n",
    "                    new_lines = lines[i+1:i+count+2]\n",
    "                    command = (\"add\", cmd, new_line_numbers,new_lines)\n",
    "                    #print(command)\n",
    "            elif lines[i].find(\"c\") > 0:\n",
    "                cmd = lines[i].split(\"c\")\n",
    "                pre = cmd[0]\n",
    "                post = cmd[1]\n",
    "                new_count=0\n",
    "                old_count=0\n",
    "                \n",
    "                if pre.find(\",\")>0:\n",
    "                    old_line_numbers = tuple(map(int, lines[i].split(\"c\")[0].split(\",\")))\n",
    "                    old_count = old_line_numbers[1]-old_line_numbers[0]+1\n",
    "                    #old_lines = lines[i+1:i+old_count+1]\n",
    "                else:\n",
    "                    old_line_numbers = int(pre)\n",
    "                    #print(type(old_line_numbers))\n",
    "                    old_count=1\n",
    "                    #old_lines = lines[i+1:i+old_count+2]\n",
    "                \n",
    "                \n",
    "                if post.find(\",\")>0:\n",
    "                    #print(\"Pre = \")\n",
    "                    #print(pre)\n",
    "                    new_line_numbers = tuple(map(int, lines[i].split(\"c\")[1].split(\",\")))\n",
    "                    new_count = new_line_numbers[1]-new_line_numbers[0]+1\n",
    "                    #new_lines = lines[i+1:i+new_count+2]\n",
    "                else:\n",
    "                    new_line_numbers = int(post)\n",
    "                    new_count=1\n",
    "                    #new_lines = lines[i+1:i+new_count+1]\n",
    "               \n",
    "                old_lines = [line[2:] for line in lines[i+1:i+old_count+1]]\n",
    "                new_lines = [line[2:] for line in lines[i+old_count+2:i+old_count+new_count+2]]\n",
    "                command = (\"change\", old_line_numbers, new_line_numbers,old_lines,new_lines)\n",
    "                #print(command)\n",
    "            elif lines[i].find(\"d\") > 0:\n",
    "                cmd = lines[i].split(\"d\")[0]\n",
    "                old_line_numbers = tuple(map(int, lines[i].split(\"d\")[0].split(\",\")))\n",
    "                count = old_line_numbers[1]-old_line_numbers[0]\n",
    "                #print(count)\n",
    "                new_lines = lines[i+1:i+count+2]\n",
    "                command = (\"del\", cmd, new_line_numbers,old_lines)\n",
    "                #print(command)\n",
    "            \n",
    "            commands.append(command)\n",
    "            while((j<len(lines)-1) and lines[j][0] in ['>','<',\"\\\\\",'-']):\n",
    "                #print(str(j-i)+\" |\"+lines[j])\n",
    "                j+=1\n",
    "            #print(\" \")\n",
    "        i=j\n",
    "    return commands\n",
    "\n",
    "with open('gdiff.txt') as f:\n",
    "    dif = f.read()\n",
    "    #print(dif)\n",
    "    #print(type(dif))\n",
    "    patch = (parse_patch(dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f9a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clone_path(path):\n",
    "    # split the path by '/'\n",
    "    path_parts = path.split('/')\n",
    "\n",
    "    # get the index of \"repo\"\n",
    "    repo_index = path_parts.index(\"repo\")\n",
    "\n",
    "    # replace \"repo\" with \"AIFiles\" in the path and join the path parts back together\n",
    "    new_path = \"/\".join(path_parts[:repo_index] + [\"AIFiles\"] + path_parts[repo_index+1:])\n",
    "\n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a771d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_info():\n",
    "    # Open the info.json file and load its contents into a Python dictionary\n",
    "    with open('info.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get the home_path value from the dictionary\n",
    "    path = data['home_path']\n",
    "    return path\n",
    "    \n",
    "def sync_AI():\n",
    "    df4 = pd.read_csv('df4.csv')\n",
    "    df2 = pd.read_csv('df2.csv')\n",
    "    df = pd.read_csv('df.csv')\n",
    "    \n",
    "    path = read_info()\n",
    "    print(\"Syncing AI :\")\n",
    "    file_paths_details = []\n",
    "    Files_to_ignore = open(path+\"/.AIIgnore\", \"r\").read().splitlines()\n",
    "    #print(\"Files and directories to ignore:\")\n",
    "    #print(Files_to_ignore)\n",
    "\n",
    "    for root, directories, files in os.walk(path):\n",
    "            # Exclude any directories that appear in the ignore list\n",
    "            directories[:] = [d for d in directories if d not in Files_to_ignore]\n",
    "            #print(\"Directories:\", directories)\n",
    "            for filename in files:\n",
    "                if filename not in Files_to_ignore:\n",
    "                    #print(filename)\n",
    "                    # Append the path to each file to the file_paths list\n",
    "                    file_paths_details.append(os.path.join(root, filename))\n",
    "\n",
    "    # Find the set difference between file_paths_details and df4[\"filepath\"]\n",
    "    new_file_paths = set(file_paths_details) - set(df4[\"filepath\"])\n",
    "    # Iterate over the new_file_paths set and create a new row for each file path\n",
    "    new_rows = []\n",
    "    for file_path in new_file_paths:\n",
    "        # Create a dictionary with the values for each column in the new row\n",
    "        row_dict = {\n",
    "            \"filepath\": file_path\n",
    "            # Add any other columns you need for the new row\n",
    "        }\n",
    "        # Append the new row to the new_rows list\n",
    "        new_rows.append(row_dict)\n",
    "        print(\"New File : \"+file_path)\n",
    "\n",
    "    # Convert the new_rows list of dictionaries to a pandas DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df4 = pd.concat([df4, new_df], ignore_index=True)\n",
    "    \n",
    "    del_file_paths = set(df4[\"filepath\"]) - set(file_paths_details)\n",
    "    \n",
    "    # Iterate over the del_file_paths set and remove the corresponding rows from dataframes\n",
    "    for file_path in del_file_paths:\n",
    "        df4 = df4[df4[\"filepath\"] != file_path]\n",
    "        df2 = df2[df2[\"filepath\"] != file_path]\n",
    "        df = df[df[\"filepath\"] != file_path]\n",
    "        print(\"Deleted File : \"+file_path)\n",
    "    \n",
    "    #display(df)\n",
    "    #display(df2)\n",
    "    display(df4)\n",
    "    \n",
    "    df_old = df\n",
    "    \n",
    "    i=0\n",
    "    for ind in df4.index:\n",
    "        #print(df4['filepath'][ind])\n",
    "        i+=1\n",
    "        if(df4['last_sync'][ind]>df4['last_updated'][ind]):\n",
    "            print(\"Updating : \"+df4['filepath'][ind])\n",
    "            file_diff = get_diff(df4['filepath'][ind],get_clone_path(df4['filepath'][ind]))\n",
    "            #print(file_diff)\n",
    "            print(\" \")\n",
    "            \n",
    "    \n",
    "    df4.to_csv(\"df4.csv\", index=False)\n",
    "    df2.to_csv(\"df2.csv\", index=False)\n",
    "    df.to_csv(\"df.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18a6b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_diff(old_file_path, new_file_path):\n",
    "    # command to generate unified diff with context lines\n",
    "    command = f'echo {old_file_path} {new_file_path}'\n",
    "\n",
    "    # run the command and capture its output\n",
    "    diff_output = subprocess.check_output(command.split()).decode('utf-8')\n",
    "\n",
    "    # return the output as a string\n",
    "    return diff_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b083705a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syncing AI :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>last_sync</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/prathameshsutone/Desktop/PR_Raiser/repo...</td>\n",
       "      <td>1.679410e+09</td>\n",
       "      <td>1.679409e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/prathameshsutone/Desktop/PR_Raiser/repo...</td>\n",
       "      <td>1.679410e+09</td>\n",
       "      <td>1.679387e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/prathameshsutone/Desktop/PR_Raiser/repo...</td>\n",
       "      <td>1.679410e+09</td>\n",
       "      <td>1.679392e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/prathameshsutone/Desktop/PR_Raiser/repo...</td>\n",
       "      <td>1.679410e+09</td>\n",
       "      <td>1.679390e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/prathameshsutone/Desktop/PR_Raiser/repo...</td>\n",
       "      <td>1.679410e+09</td>\n",
       "      <td>1.679131e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath     last_sync  \\\n",
       "0  /Users/prathameshsutone/Desktop/PR_Raiser/repo...  1.679410e+09   \n",
       "1  /Users/prathameshsutone/Desktop/PR_Raiser/repo...  1.679410e+09   \n",
       "2  /Users/prathameshsutone/Desktop/PR_Raiser/repo...  1.679410e+09   \n",
       "3  /Users/prathameshsutone/Desktop/PR_Raiser/repo...  1.679410e+09   \n",
       "4  /Users/prathameshsutone/Desktop/PR_Raiser/repo...  1.679410e+09   \n",
       "\n",
       "   last_updated  \n",
       "0  1.679409e+09  \n",
       "1  1.679387e+09  \n",
       "2  1.679392e+09  \n",
       "3  1.679390e+09  \n",
       "4  1.679131e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating : /Users/prathameshsutone/Desktop/PR_Raiser/repo/index.html\n",
      "/Users/prathameshsutone/Desktop/PR_Raiser/repo/index.html /Users/prathameshsutone/Desktop/PR_Raiser/AIFiles/index.html\n",
      "\n",
      " \n",
      "Updating : /Users/prathameshsutone/Desktop/PR_Raiser/repo/styles.css\n",
      "/Users/prathameshsutone/Desktop/PR_Raiser/repo/styles.css /Users/prathameshsutone/Desktop/PR_Raiser/AIFiles/styles.css\n",
      "\n",
      " \n",
      "Updating : /Users/prathameshsutone/Desktop/PR_Raiser/repo/dummy_1.txt\n",
      "/Users/prathameshsutone/Desktop/PR_Raiser/repo/dummy_1.txt /Users/prathameshsutone/Desktop/PR_Raiser/AIFiles/dummy_1.txt\n",
      "\n",
      " \n",
      "Updating : /Users/prathameshsutone/Desktop/PR_Raiser/repo/login-page.js\n",
      "/Users/prathameshsutone/Desktop/PR_Raiser/repo/login-page.js /Users/prathameshsutone/Desktop/PR_Raiser/AIFiles/login-page.js\n",
      "\n",
      " \n",
      "Updating : /Users/prathameshsutone/Desktop/PR_Raiser/repo/.AIIgnore\n",
      "/Users/prathameshsutone/Desktop/PR_Raiser/repo/.AIIgnore /Users/prathameshsutone/Desktop/PR_Raiser/AIFiles/.AIIgnore\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('df.csv')\n",
    "df2 = pd.read_csv('df2.csv')\n",
    "df4 = pd.read_csv('df4.csv')\n",
    "\n",
    "sync_AI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
