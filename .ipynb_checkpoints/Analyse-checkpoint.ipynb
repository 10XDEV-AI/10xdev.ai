{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a5a14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/RESULTS.md\" contains a record of benchmark results for various applications. The benchmarks were run on different dates, and each benchmark is categorized as either \"Ran,\" \"Works,\" or \"Perfect.\" The file also includes notes on the errors encountered during each benchmark. The errors range from notifications not working to incorrect file names and dependencies being used incorrectly. Some of the errors were easy to fix, while others required more attention. Overall, the benchmarks show the progress and improvements made in the applications over time.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/timer_app/prompt\" contains a prompt or task description for creating a simple timer app using HTML, CSS, and JavaScript. The app should allow users to set a countdown timer and receive an alert when the time is up. This prompt serves as a guideline for developers to create the desired functionality in their timer app.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"prompt\" in the \"file_explorer\" directory contains a Python script that creates a command-line interface (CLI) tool for a basic file explorer. This tool enables users to navigate through directories, view the contents of files, and perform basic file operations such as copying, moving, and deleting files.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/todo_list/prompt\" provides instructions to create a basic to-do list application using HTML, CSS, and JavaScript. The app should allow users to add, edit, and delete tasks. Additionally, the tasks should be stored in the local storage of the user\\'s device.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/pomodoro_timer/prompt\" contains a prompt or task description for developing a Pomodoro timer app using HTML, CSS, and JavaScript. The app should allow users to set work and break intervals and receive notifications when it\\'s time to switch between work and break sessions.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/currency_converter/prompt\" provides instructions for building a currency converter app. The app should use an API to fetch exchange rates and allow users to convert between different currencies. The frontend of the app should be built using HTML, CSS, and JavaScript, while the backend should be implemented using Node.js.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/image_resizer/prompt\" contains a prompt or task description. It instructs the user to create a command-line interface (CLI) tool using Python that can resize images based on the specified width and height. The prompt also specifies that the Pillow library should be used for image manipulation.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"prompt\" in the \"benchmark/file_organizer\" directory contains instructions on how to create a command-line interface (CLI) tool using Python. This tool is designed to organize files in a directory by sorting them based on their file types, such as images, documents, and audio files. The tool will move each file into the corresponding folder based on its file type, helping to keep the directory organized and easier to navigate.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"benchmark/password_generator/prompt\" contains a prompt or description for creating a password generator CLI tool in Python. The tool is designed to generate strong and random passwords based on specific criteria set by the user. These criteria may include the desired length of the password and the types of characters to be included, such as letters, numbers, and symbols.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file benchmark/url_shortener/prompt provides a prompt for creating a URL shortener app. The app should be built using HTML, CSS, JavaScript, and a backend language like Python or Node.js. The app should allow users to input a long URL and generate a shortened version of it. When the shortened URL is accessed, it should redirect the user to the original URL. The app should also store the shortened URLs in a database for future reference.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file benchmark/markdown_editor/prompt provides a prompt to build a basic markdown editor using HTML, CSS, and JavaScript. The goal is to create a user interface where users can input markdown text and see the formatted output in real-time. This suggests that the editor should have features to interpret and display markdown syntax, allowing users to preview their content as they type.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of the file docker/Dockerfile specify the instructions for building a Docker image. The image is based on the python:3.9-slim image. The file starts by updating the package lists and installing the packages sudo, tk, and tcl. The working directory is set to /app. The contents of the current directory are copied into the /app directory of the image. Additionally, the entrypoint.sh script from the docker directory is copied into the /app directory. The next step is to install the project in editable mode using pip. Finally, the entrypoint for the container is set to execute the entrypoint.sh script using bash.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file provides instructions on how to get started using Docker to run the gpt-engineer project. It includes steps for running the project using the Docker CLI and the Docker Compose CLI. The instructions cover building the Docker image, running the container, setting the OPENAI_API_KEY, and mounting the project folder into the container.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of the file docker/entrypoint.sh are a shell script that sets the project directory to \"/project\" and then runs the \"gpt-engineer\" script with the project directory and any additional arguments passed to the script. After running the script, it patches the permissions of the generated files in the project directory to be owned by nobody except for the prompt file. It does this by iterating over each item in the project directory, excluding the prompt file, and changing the ownership to nobody:nogroup and setting the permissions to 777.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"projects/example/prompt\" contains information about a project that involves writing a snake game in Python. The project follows the Model-View-Controller (MVC) architectural pattern, with the components of the game split into separate files. Additionally, the game will have keyboard control functionality.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `tests/test_chat_to_files.py` contains a series of test cases for the `to_files` function in the `gpt_engineer.chat_to_files` module. The `to_files` function takes a chat message as input and extracts code snippets and file names from the message. It then creates files with the extracted code snippets and saves them in a workspace dictionary. The test cases cover different scenarios, such as code snippets with and without square brackets, code snippets with special characters in the file name, and code snippets with different formatting styles. Each test case asserts that the expected files and their contents are correctly created in the workspace dictionary.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"tests/test_collect.py\" contains a test function called \"test_collect_learnings\". This function tests the \"collect_learnings\" function from the \"gpt_engineer.collect\" module. The test uses the \"monkeypatch\" fixture to set environment variables and mock certain functions. It creates a mock model, temperature, steps, and database objects. It then calls the \"collect_learnings\" function with these objects. After that, it extracts the learning from the database and compares it with the expected values. Finally, it asserts that certain function calls were made and certain values are present in the extracted learning. The file also includes a conditional block that runs the test when the file is executed directly.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file tests/test_db.py contains several test functions for the DB class and the DBs class from the gpt_engineer.db module. \\n\\nThe first test function, test_DB_operations, tests the initialization of a DB object, setting and getting values using the __setitem__ and __getitem__ methods, raising errors for non-existent keys and invalid values.\\n\\nThe second test function, test_DBs_initialization, tests the initialization of multiple DB objects and the creation of a DBs instance, asserting that each attribute of the DBs instance is an instance of the DB class.\\n\\nThe third test function, test_invalid_path, tests the behavior of the DB class when given an invalid path, raising either a PermissionError or OSError.\\n\\nThe fourth test function, test_large_files, tests the ability of the DB class to handle large files, writing and reading a large file.\\n\\nThe fifth test function, test_concurrent_access, tests the concurrent access to a DB object by multiple threads, ensuring that all expected data was written and can be retrieved.\\n\\nThe sixth test function, test_error_messages, tests the error messages raised by the DB class when given invalid values.\\n\\nThe seventh test function, test_DBs_instantiation_with_wrong_number_of_arguments, tests the instantiation of a DBs object with the wrong number of arguments, raising a TypeError.\\n\\nThe eighth test function, test_DBs_dataclass_attributes, tests the attributes of a DBs instance, asserting that each attribute corresponds to the corresponding DB object.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The file tests/test_ai.py contains a test case for the AI class from the gpt_engineer.ai module. The test case is marked with pytest's xfail decorator, indicating that it is expected to fail. The reason for the expected failure is that the constructor of the AI class assumes API access, which is not available in the testing environment. The test case simply creates an instance of the AI class and does not include any assertions to test the behavior of its methods. There is a TODO comment suggesting that assertions should be added to test the behavior of the methods.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"tests/steps/test_archive.py\" contains a test function called \"test_archive\". This function tests the \"archive\" function from the \"gpt_engineer.db\" module. The test sets up a temporary directory and creates a list of DB objects using the \"DB\" class. It then calls the \"archive\" function with the DBs instance. The test freezes the current time using the \"freeze_at\" function and asserts that certain directories do not exist and that a new directory is created in the \"archive\" directory with a specific timestamp. The test is run twice with different timestamps to ensure the correct behavior of the \"archive\" function.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"DOCS_BUILDING.md\" provides instructions on how to build documentation using Sphinx with Read the Docs. It explains the basic structure of a Sphinx docs project and how to set up the project using the readthedocs project template. The file also provides links to useful resources such as the Sphinx documentation, the Read the Docs build configuration file, and the requirements.txt file for Python dependencies. It includes an example project usage section that demonstrates how to build and view the documentation project locally. The file also outlines the structure of the project\\'s documentation and provides a link to the Read the Docs tutorial for further guidance.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file are being included from the README.md file located in the parent directory. The included content is being parsed using the myst_parser.sphinx_ parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `docs/index.rst` is the main documentation file for GPT-ENGINEER. It contains a table of contents that organizes the documentation into different sections. The sections include an introduction, user guides, core components, harmony of AI, DB, & steps, chat parsing & self-execution, contributing guides, and package API. Each section has a list of subtopics that provide more detailed information on various aspects of GPT-ENGINEER. Additionally, the file includes indices and tables for easy navigation within the documentation.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file is an API reference for the gpt_engineer package. It provides documentation for various modules and functions within the package. The modules covered in the reference include gpt_engineer.ai, gpt_engineer.chat_to_files, gpt_engineer.collect, gpt_engineer.db, gpt_engineer.learning, gpt_engineer.main, and gpt_engineer.steps. Each module is described and the functions within each module are listed with brief descriptions.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file are a Python script that is used to auto-generate an API reference file called \"api_reference.rst\". The script uses the pathlib and glob modules to find all Python files in a specific directory, and then parses those files to extract information about classes and functions. It constructs a documentation string in reStructuredText format, including sections for each module, classes, and functions. The script then writes the generated documentation to the \"api_reference.rst\" file.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file include a link to a roadmap document, which is specified by the inclusion of the file \"ROADMAP.md\". The parser used for this file is \"myst_parser.sphinx_\".'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file is a makefile for Sphinx documentation. It sets variables for the Sphinx build process, such as the Sphinx options, the Sphinx build command, the project name, the source directory, and the build directory. It also includes a help target that displays the available make targets and their descriptions. Additionally, it includes a catch-all target that routes all unknown targets to Sphinx using the make mode option.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `docs/conf.py` is a configuration file for the Sphinx documentation generator. It sets various options and values for the documentation build process. Some of the key configurations include specifying the project name, version, and author, as well as the theme to use for the HTML output. It also includes configurations for extensions such as autodoc, which generates documentation from code comments, and sphinx_copybutton, which adds a copy button to code blocks.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `docs/contributing_link.rst` includes the contents of the file `.github/CONTRIBUTING.md` using the `myst_parser.sphinx_` parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file provides instructions on how to use the file-processor in a project. It explains the setup process, including setting up the OpenAI API key, and provides steps on how to run the file-processor. It also mentions that by running the file-processor, the user agrees to the terms of use. Finally, it mentions that the generated files can be checked in a specific folder and provides a link for running the file-processor in the browser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file is a batch script used for generating Sphinx documentation. It sets up the necessary environment variables and checks if Sphinx is installed. If Sphinx is not found, it provides instructions on how to install it. The script then calls the Sphinx module with the specified command and passes the necessary arguments. The available commands include \"help\" for displaying help information and other commands for building the documentation. Finally, the script restores the previous working directory.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file include a link to the code of conduct document located at `.github/CODE_OF_CONDUCT.md`. The document is parsed using the myst_parser.sphinx_ parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file provides instructions for installing the gpt-engineer package. The preferred method is to install it using pip by running the command \"pip install gpt_engineer\" in the terminal. If pip is not installed, a Python installation guide is provided. Alternatively, the package can be downloaded from the Github repository and installed using pip.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file include a link to a disclaimer file located at \"../DISCLAIMER.md\". The file is parsed using the myst_parser.sphinx_ parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file include a link to another file called \"RESULTS.md\" located in the \"benchmark\" directory. The link is included using the \"include\" directive and specifies the parser to be used as \"myst_parser.sphinx_\".'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file are being imported from another file called \"WINDOWS_README.md\" using the \"include\" directive. The imported content is being parsed using the \"myst_parser.sphinx_\" parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of the file `docs/terms_link.rst` include a directive to include the contents of the file `TERMS_OF_USE.md` using the `myst_parser.sphinx` parser.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gate.md\" provides an introduction to GPT-Engineer, an open-source project that utilizes OpenAI\\'s GPT-4 model to automate software engineering tasks. It explains that GPT-Engineer can generate code, clarify instructions, and generate specifications by interacting with the GPT-4 model in a conversational manner. The file describes the core components of GPT-Engineer, including the AI class, DB class, and Steps module. It also provides information on how to use GPT-Engineer, its development and community aspects, and references to related documentation and the GitHub repository.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `steps_module.md` provides an overview of the steps module in the GPT-Engineer system. The module defines a series of steps that the AI can perform, such as generating code, clarifying instructions, generating specifications, and more. Each step is a function that takes an AI and a set of databases as arguments and returns a list of messages. The file lists the steps defined in the module, including functions like `simple_gen`, `clarify`, `gen_spec`, `gen_unit_tests`, and more. It also mentions different configurations of steps that are defined in the module, such as `DEFAULT`, `BENCHMARK`, `TDD`, and others. These configurations are lists of steps that are run in a specific order. The file concludes by highlighting the flexibility of the steps module in allowing different sequences of steps to be combined for different outcomes.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The `main.py` script is the entry point of the application and sets up the AI model and databases. It uses the Typer library to create a command-line interface. The script provides options such as the project path, whether to delete existing files, the AI model to use, the temperature parameter for the model, the steps configuration, verbosity of logging, and a run prefix. To run the script, you can use the provided command with the appropriate values. The script offers flexibility and user-friendliness, allowing easy configuration of the AI model and steps, and provides detailed logging for debugging and understanding the system's behavior.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `db_class.md` provides an introduction to the DB class in the GPT-Engineer system. The DB class is a key-value store that stores data as files in a directory. It has methods such as `__init__`, `__contains__`, `__getitem__`, and `__setitem__` for creating the directory, checking if a key exists, retrieving a value associated with a key, and setting a value for a key, respectively. The file also introduces the DBs class, which is a dataclass containing instances of the DB class for different types of data. The DBs class includes databases for memory, logs, preprompts, input, and workspace. Overall, the DB and DBs classes provide a flexible way to manage data in the GPT-Engineer system.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `preprompts.md` provides an overview of the predefined prompts available in GPT-Engineer. These prompts guide the AI in performing various software engineering tasks. The prompts are stored as text files in the `gpt_engineer/preprompts` directory. The file lists and describes each prompt, including their purpose and expected output. The prompts cover tasks such as fixing code, generating code based on instructions, following best practices, seeking clarification on instructions, reviewing specifications, creating program specifications, writing unit tests, and generating code based on user-defined feedback. GPT-Engineer aims to automate software engineering tasks using GPT-4 and encourages the AI to produce high-quality code by following best practices and reasoning through the tasks.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"scripts.md\" provides an overview of the Python scripts included in the GPT-Engineer repository. These scripts offer various functionalities such as running benchmarks, cleaning benchmark folders, printing chat logs, and rerunning conversations with the AI. The \"benchmark.py\" script runs benchmarks for each folder in the benchmark directory and saves the results to a log file. The \"clean_benchmarks.py\" script deletes all files and directories in the benchmark folders except for the main_prompt file. The \"print_chat.py\" script prints chat conversations in a human-readable format with colored messages based on the sender\\'s role. The \"rerun_edited_message_logs.py\" script reruns conversations with the AI after editing message logs and saves the new messages to an output file. These scripts enhance the functionality and usability of the GPT-Engineer system.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file is a table of contents for a document or guide. It outlines the different sections and subsections of the document, including an introduction, user guide, core components, harmony of AI, DB, and steps, and a section on chat parsing and self code execution. Each section is numbered and includes links to specific sections within the document.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"quick_overview.md\" provides a quick overview of the GPT-Engineer project, which uses GPT-4 to automate software engineering tasks. It describes the core components of the project, including the AI class, the Chat to Files module, the DB class, the Main Script, and the Steps module. Each component is explained in detail, along with its purpose and functionality. The Steps module is particularly highlighted, as it defines a series of steps that can be run in the main script to perform various tasks such as generating code, clarifying requirements, generating specifications, and executing scripts. Different configurations are also mentioned, which allow users to select specific sets of steps to run.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `chat_parsing.md` provides an overview of the `chat_to_files.py` module and its role in the self-execution of code generated by the AI. The module is responsible for parsing the chat generated by the AI, extracting code blocks, and saving them as files in the workspace. The file describes the functions defined in the module, including `parse_chat()` and `to_files()`, which are used to extract filenames and file contents from the chat and save them to the workspace. The file also explains how the module enables the self-execution of code by allowing GPT-Engineer to execute the code in the saved files. However, it emphasizes the need for caution when using this feature, as the generated code may not always produce the expected results and could potentially be harmful.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The file `repository_stats.md` provides an overview of the GPT-Engineer repository, a project developed by Anton Osika that uses GPT-4 to automate software engineering processes. The repository is written in Python and is publicly available on GitHub. The file also includes information on how to contribute to the project, links to the roadmap, projects, and issues tab on GitHub, as well as a link to an example of the project in action. The example includes a video demonstrating the project's functionality.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `ai_class.md` provides documentation for the AI Class, which is the main interface to the GPT-4 model. The class has several methods including `__init__`, `start`, `fsystem`, `fuser`, `fassistant`, and `next`. The `__init__` method initializes the AI class with the specified model and temperature parameters. The `start` method starts a conversation with the AI by providing a system message and a user message. The `fsystem`, `fuser`, and `fassistant` methods format system, user, and assistant messages respectively. The `next` method continues a conversation with the AI by providing a list of messages and an optional prompt.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"harmony_db_ai_steps.md\" provides an overview of the core components of GPT-Engineer, a tool that uses AI to automate software engineering tasks. The three main components are the AI class, the DB class, and the steps module. The AI class is responsible for interacting with the GPT-3 model and generating responses. The DB class represents a simple database that stores data used by the system. The steps module defines a series of functions that control the flow of the system and perform specific tasks, such as generating code or clarifying instructions. The file also provides examples of how to create and use custom steps in the system.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `scripts/print_chat.py` is a Python script that imports the `json` module and uses the `typer` library to create a command-line interface. It defines a function `pretty_print_conversation` that takes a list of messages as input and formats and prints them to the console. The function assigns colors to different roles (system, user, assistant, function) and formats the messages accordingly. The script also defines a `main` function that takes a path to a JSON file containing the messages as input. It opens the file, loads the messages using `json.load`, and then calls the `pretty_print_conversation` function to print the formatted messages. Finally, the script checks if it is being run as the main module and calls the `app` function from `typer` to execute the command-line interface.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"scripts/benchmark.py\" contains a Python script that runs benchmarks for a given set of folders. It iterates over the folders in the \"benchmark\" directory and runs a benchmark for each folder. The script uses subprocess to run a command-line command that executes a Python module called \"gpt_engineer.main\" with specific arguments. It also writes the output of the benchmark to a log file. After running all the benchmarks, the script generates a report based on the results and prompts the user to append the report to a results file. The script also includes helper functions for generating the report, inserting a markdown section into a file, and asking the user for a yes or no response. The main function is executed when the script is run directly.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file are a Python script that cleans up benchmark folders. It lists all the folders in the \"benchmark\" directory and for each folder, it deletes all files and subfolders except for the \"prompt\" and \"main_prompt\" folders. The script uses the `os` and `shutil` modules to delete the files and folders. The script is executed when the file is run directly.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `rerun_edited_message_logs.py` is a Python script that imports the `json` and `pathlib` modules. It defines a command-line application using the `typer` library. The main function of the application takes in several parameters, including the path to a file containing messages, an optional output path, the model name, and a temperature value. It creates an instance of the `AI` class from the `gpt_engineer.ai` module, and then loads the messages from the specified file using `json.load()`. It then uses the `ai.next()` method to process the messages and generate a response. If an output path is provided, it writes the generated response to files and saves the content as JSON in a file named \"all_output.txt\". Finally, the application is executed when the script is run directly.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `gpt_engineer/steps.py` contains a collection of functions that define the steps to be executed in the GPT-Engineer pipeline. These steps include generating code, clarifying user input, generating specifications, generating unit tests, generating code based on unit tests, executing code, and collecting human reviews. The specific steps to be executed depend on the configuration specified. The file also includes helper functions for setting up system prompts, getting user prompts, and getting the name of the current function.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/db.py\" contains a class called \"DB\" which represents a simple database that stores its data as files in a directory. The class has methods for checking if a file exists in the database, getting the content of a file, setting the content of a file, and getting the content of a file with a default value if the file does not exist. The file also includes a dataclass called \"DBs\" which represents a collection of different databases. Additionally, there is a function called \"archive\" which archives the memory and workspace databases by moving them to a specified directory with a timestamp.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `gpt_engineer/collect.py` contains a function `send_learning` that sends learning data to RudderStack for analysis. The function is only called if consent is given to share data, and the data is used to improve the `gpt-engineer` and handle more use cases. The file also contains a function `collect_learnings` that collects the learning data and sends it to RudderStack. If the learning data is too big, some parts of it are removed before sending. Additionally, the file includes a function `steps_file_hash` that computes the SHA-256 hash of the steps file.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/chat_to_files.py\" contains several functions related to parsing and manipulating chat messages that contain code blocks. \\n\\nThe \"parse_chat\" function takes a chat message as input and extracts all code blocks from it. It returns a list of tuples, where each tuple contains a filename and a code block.\\n\\nThe \"to_files\" function parses a chat message and adds all extracted files to a workspace. It takes the chat message and the workspace as input.\\n\\nThe \"overwrite_files\" function replaces the AI files with older local files. It takes the chat message, the database containing the workspace, and a dictionary mapping file names to file paths of the local files as input.\\n\\nThe \"get_code_strings\" function reads a file_list.txt file and returns a dictionary mapping file names to their content.\\n\\nThe \"format_file_to_input\" function formats a file string to use as input to the AI agent. It takes the name of the file and its content as input and returns the formatted file string.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/domain.py\" imports the modules \"Callable\", \"List\", and \"TypeVar\" from the \"typing\" module. It also imports the \"AI\" class from the \"gpt_engineer.ai\" module and the \"DBs\" class from the \"gpt_engineer.db\" module. It defines a type variable \"Step\" that is bound to a callable function that takes an instance of the \"AI\" class and an instance of the \"DBs\" class as arguments and returns a list of dictionaries.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/ai.py\" contains the implementation of the AI class, which is responsible for managing the conversation with the GPT model. The AI class has methods for initializing the class, starting a conversation, creating system, user, and AI messages, advancing the conversation, serializing and deserializing messages, updating the token usage log, formatting the token usage log, counting the number of tokens in a text or a list of messages, and retrieving the fallback model. The file also includes helper functions for creating the chat model, getting the tokenizer, and serializing messages.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `gpt_engineer/file_selector.py` contains a class `DisplayablePath` that represents a displayable path in a file explorer. It also contains a class `TerminalFileSelector` that allows the user to select files from a directory and display the selected files in the terminal. The file also includes functions for checking if a path is not hidden or in the `__pycache__` directory, and for asking the user to select files either through the command-line or a file explorer.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/learning.py\" contains several functions and data classes related to the learning process in the GPT Engineer project. It includes functions for collecting user consent to store data, asking users to review generated code, converting logs to a string, extracting learning data from steps and databases, and generating a unique user ID for the current session. The file also includes data classes for representing reviews and learning data.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file `gpt_engineer/main.py` is a Python script that contains the main functionality of the GPT Engineer application. It imports various modules and functions, including `logging`, `os`, `pathlib`, `openai`, `typer`, and `dotenv`. The script defines a CLI app using the `typer` module and includes a `main` function that serves as the entry point for the application. The `main` function takes several command-line arguments and performs various tasks, such as loading environment variables, initializing an AI model, setting up database connections, executing steps based on the provided configuration, logging messages, and collecting learnings. The script also includes a conditional block that runs the `main` function when the script is executed directly.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file provides instructions for an expert developer who is tasked with fixing an issue or creating a new functionality in an existing codebase. The developer will receive the code one by one and needs to comprehend what needs to be modified by understanding the implementation of the received code and the interconnections between each file, function, and class. The files are organized with the filename followed by the code. The developer should use the received code as a base to implement the requested functionality, ensuring compatibility between different files and following the same coding language and framework. If unsure, the developer should write a plausible implementation. Finally, the developer should double-check that all parts of the architecture are present in the files before finishing.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file gpt_engineer/preprompts/unit_tests contains a prompt for generating unit tests based on a specification. It suggests that the tests should be simple yet cover all the functionality. The prompt assumes that the developer is using Test Driven Development (TDD) and encourages them to write tests that align with the given specification.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/preprompts/roadmap\" provides instructions for writing code. It emphasizes the need to provide a comprehensive implementation of the architecture, ensuring that every detail is translated into code. The instructions suggest that the answer should be lengthy, indicating the importance of thoroughness and attention to detail in the coding process.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"clarify\" in the \"gpt_engineer/preprompts\" directory provides instructions for the GPT-3 model. It states that the model should read instructions without actually executing them, focusing instead on seeking clarification. The first step is to summarize a list of very brief bullet points that require clarification. After that, the model should select one question for clarification and wait for a response from the user.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/preprompts/spec\" provides guidance on creating a high-quality specification for a program. It emphasizes the importance of being explicit about the program\\'s features and providing clear details to avoid any ambiguity. The file also suggests outlining the names of core classes, functions, and methods, along with brief comments on their purpose. The specification created using this guidance will serve as the foundation for the program\\'s implementation.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"gpt_engineer/preprompts/respec\" provides a set of prompts for a pragmatic principal engineer at Google who is tasked with reviewing a specification for a new feature. The engineer is asked to provide feedback on potential issues with the instructions, missing components in the specification, and opportunities for simplification. The engineer is also instructed to make educated assumptions for unclear items and communicate those assumptions when implementing the feature. The engineer is encouraged to think step by step to ensure that no important details are overlooked.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The contents of this file provide guidelines and preferences for organizing code and creating files in the context of a GPT (Generative Pre-trained Transformer) engineering project. It suggests separating different classes into different files and using the programming language requested by the user. For Python, it recommends creating a requirements.txt file and utilizing tools like pytest and dataclasses. Similarly, for NodeJS, it suggests creating a package.json file. The file also emphasizes the importance of adding comments to describe the purpose of function definitions and to explain complex logic. Additionally, it advises following best practices for folder/file structure and packaging the project based on the requested programming language.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This file provides instructions for generating code files in a specific format. It suggests a step-by-step approach to ensure that the code is implemented correctly. The instructions include laying out the names of core classes, functions, and methods, as well as providing comments on their purpose. The file emphasizes the use of markdown code blocks to format the code files. It also emphasizes the need for fully functional code without any placeholders. The instructions suggest starting with the \"entrypoint\" file and then proceeding to the imported files in a hierarchical manner. The file also emphasizes the importance of following language and framework appropriate file naming conventions and ensuring compatibility between different code files. The instructions also mention the inclusion of module or package manager dependency definition files and a final check to ensure that all parts of the architecture are present in the generated files.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The file \"fix_code\" is a prompt for an AI model to act as a super smart developer who has been assigned the task of fixing a program. The prompt instructs the AI to fill in any placeholders in the code and provide a fully functioning, well-formatted code with minimal comments and no bugs. The AI is expected to return the complete new code in the same format as the original.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = \"../user/\" + \"prathamthepro@gmail.com\" + \"/AIFiles/\" + \"gpt-engineer\" + \".csv\"\n",
    "fs = pd.read_csv(filename)\n",
    "\n",
    "for index in range(0,71):\n",
    "    display(fs['summary'][index])\n",
    "    display(fs['role'][index])\n",
    "    print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6ec7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   benchmark/RESULTS.md\n",
       "1             benchmark/timer_app/prompt\n",
       "2         benchmark/file_explorer/prompt\n",
       "3             benchmark/todo_list/prompt\n",
       "4        benchmark/pomodoro_timer/prompt\n",
       "                     ...                \n",
       "66          gpt_engineer/preprompts/spec\n",
       "67        gpt_engineer/preprompts/respec\n",
       "68    gpt_engineer/preprompts/philosophy\n",
       "69      gpt_engineer/preprompts/generate\n",
       "70      gpt_engineer/preprompts/fix_code\n",
       "Name: file_path, Length: 71, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fs[pd.isnull(fs[\"role\"])]['file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cadf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
